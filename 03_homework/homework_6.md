# Homework 6: Reflecton

- Due on Saturday, May 25 at 11:59pm
- Weight: 8% of total grade

<br>

**Write**: Reflect on your previous work and how you would adjust to include ethics and inequity components. Total length should be a few paragraphs, no more than one page.

------------------------------------------------------------------------------------
Machine Learning and neural networks require humans to create, train, build and maintain systems.  It  involves preparing, cleaning and labelling data by humans. Unethical and biased systems get created  through incomplete data and biased human judgment and decisions. The article “Neural nets are just people all the way down” by Vicky Boykis highlighted that even though neural networks are automated, they still rely on human intelligence, effort, and judgment at every stage of development.

Engineers who design and implement these ML systems often implement business rules that revolve around social norms and traditions that can severely impact the life of individuals who use these systems. For example, the article “When Databases Get to Define Family” by Rida Qadri talks about how Pakistan's National Database and Registration Authority (NADRA) affected the day-to-day life of a Pakistani citizen, Riz, whose mother decided to retain her maiden name resulting in the database not recognizing his parents as married. This prevented Riz from getting an ID, and accessing essential services like banking, health, voting and employment. The NADRA  system encodes social norms and relies on family ties rather then bio metrics. It does not support individuals having non-traditional family structure, such as orphans, children born out of wedlock, LGBTQ+, single parents and unmarried couples. It is important to address these scenarios when designing fair and ethical AI systems, in order to prevent unintended consequences.

There is need for using more flexible database design that does not enforce rigid social norms. For instance, using an ENUM data type for gender can allow for easier updates and inclusivity. Database schema should allow for individual records to exist without family trees. Implementing advanced bio metric technologies such as facial recognition and fingerprints can provide verification that does not rely on rigid family based rules. Receiving feedback from representatives from all community groups and continuing to make changes to incorporate suggestions is essential to building systems that are ethical and not biased,

Data that is collected to train models should be from diverse data groups, making sure that under represented groups are accounted for. The data should also be diverse so that biases are reduced. Also, proper and well informed consent should be taken from individuals explaining them how their data will be used. There needs to be ethical guidelines and standards for development and deployment of automated systems that use Neural networks. The effects of AI systems – its social impact on different social groups, should always be monitored. These systems should always allow humans to review and override any decisions taken by them.  In order to mitigate bias and ensure fairness, there should be tools that detect bias and have constraints that ensure equity across different social groups. 

Ethical and unbiased AI systems can be implemented by ensuring ethical, diverse and inclusive data collection, by involving broad range of social groups, establishing transparent processes, and robust and fair regulatory frameworks. As a principle, care needs to be taken that any AI system does not cause harm to the very citizens it is supposed to make life easier for. This can be done by having a proper governance process and independent oversight, allowing continuous feedback to help improve the system.
